{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding of run-length encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle, shape): \n",
    "    '''     \n",
    "    mask_rle: run-length as string formated (start length)     \n",
    "    shape: (height,width) of array to return      \n",
    "    Returns numpy array, 1 - mask, 0 - background      \n",
    "    ''' \n",
    "    s = mask_rle.split() \n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])] \n",
    "    starts -= 1 \n",
    "    ends = starts + lengths \n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8) \n",
    "    for lo, hi in zip(starts, ends): \n",
    "         img[lo:hi] = 1 \n",
    "    return img.reshape(shape).T # Needed to align to RLE direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get masks and store in hashmap\n",
    "def get_masks(file):\n",
    "    segm = csv.reader(open(file, 'r'))\n",
    "    masks = {}\n",
    "\n",
    "    next(segm)\n",
    "       \n",
    "    while True:\n",
    "        try:\n",
    "            curr = next(segm);\n",
    "            if curr[0] not in masks:\n",
    "                masks[curr[0]] = []\n",
    "            masks[curr[0]].append(curr[1])\n",
    "        except StopIteration:\n",
    "            break\n",
    "        \n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masks_decode(masks):\n",
    "    for i in range(len(masks)):\n",
    "        for j in range(len(masks[i])):\n",
    "            masks[i][j] = rle_decode(masks[i][j], (768,768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_segmentation_mask(img):\n",
    "#     segmentation_mask = np.zeros((768,768), dtype=np.uint8)\n",
    "#     og_image = Image.open(f'airbus-ship-detection/train_v2/{img}')\n",
    "#     adjusted_img = og_image.rotate(90).transpose(Image.FLIP_TOP_BOTTOM)\n",
    "#     img_arr = np.asarray(adjusted_img).copy()\n",
    "        \n",
    "#     img_arr[mask == 1] = [255,255,255]\n",
    "\n",
    "#     segmentation_image = Image.fromarray(img_arr)\n",
    "#     segmentation_image.save(f'sample_imgs/{img}_segmentation_result.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "from torchvision.ops.boxes import masks_to_boxes\n",
    "from torchvision import tv_tensors\n",
    "from torchvision.transforms.v2 import functional as F\n",
    "import torch\n",
    "import os\n",
    "\n",
    "class ShipDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, size, masks, transforms=None, train=True):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.imgs = list(masks.keys())[:size]\n",
    "        self.masks = list(masks.values())[:size]\n",
    "        if train: masks_decode(self.masks)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #load image\n",
    "        img_name = os.path.join(self.root, 'train_v2', self.imgs[idx])\n",
    "        image = read_image(img_name)\n",
    "        \n",
    "        num_objs = len(self.masks[idx])\n",
    "        # get bounding boxes coordinates for each mask\n",
    "        boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
    "        area = torch.zeros((0,), dtype=torch.float32)\n",
    "        \n",
    "        if sum(sum(self.masks[idx][0])) != 0:\n",
    "            masks = torch.stack([torch.tensor(m, dtype=torch.uint8) for m in self.masks[idx]])\n",
    "            boxes = masks_to_boxes(masks)\n",
    "            area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        \n",
    "        # there is only one class\n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "        \n",
    "        image = tv_tensors.Image(image)\n",
    "        \n",
    "        target = {}\n",
    "        target[\"boxes\"] = tv_tensors.BoundingBoxes(boxes, format='xyxy', canvas_size=F.get_size(image))\n",
    "        target[\"masks\"] = tv_tensors.Mask(self.masks[idx])\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = self.imgs[idx][:-4]\n",
    "        target[\"area\"] = area\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            image, target = self.transforms(image, target)\n",
    "        \n",
    "        return image, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2 as T\n",
    "\n",
    "def get_transforms(train):\n",
    "    transforms = []\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    transforms.append(T.ToDtype(torch.float, scale=True))\n",
    "    transforms.append(T.ToPureTensor())\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "masks_encoded = get_masks('airbus-ship-detection/train_ship_segmentations_v2.csv')\n",
    "\n",
    "data_size = 1000\n",
    "\n",
    "dataset = ShipDataset('airbus-ship-detection', data_size, masks_encoded, get_transforms(train=True))   \n",
    "dataset_test = ShipDataset('airbus-ship-detection', data_size, masks_encoded, get_transforms(train=False), train=False)\n",
    "\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "data_train = torch.utils.data.Subset(dataset, indices[:-50])\n",
    "data_test = torch.utils.data.Subset(dataset_test, indices[-50:])\n",
    "   \n",
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "    data_train, \n",
    "    batch_size=2, \n",
    "    shuffle=True, \n",
    "    num_workers=0, \n",
    "    collate_fn=utils.collate_fn\n",
    ")\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    data_test, \n",
    "    batch_size=1, \n",
    "    shuffle=False, \n",
    "    num_workers=0, \n",
    "    collate_fn=utils.collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'backbone_name' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models.detection import FasterRCNN, MaskRCNN\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "\n",
    "backbone = resnet_fpn_backbone('resnet101', pretrained=True)\n",
    "\n",
    "model = MaskRCNN(backbone, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For Training\n",
    "# images, targets = next(iter(data_loader))\n",
    "# images = list(image for image in images)\n",
    "# targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "# output = model(images,targets)   # Returns losses and detections\n",
    "# print(output)\n",
    "# # loss = loss_function(output, targets)\n",
    "\n",
    "# #For inference\n",
    "# model.eval()\n",
    "# x = [torch.rand(3, 786, 786),torch.rand(3, 786, 786)]\n",
    "# predictions = model(x)           # Returns predictions\n",
    "# print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting device\n",
    "device = torch.device('mps') if torch.backends.mps.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "num_epoch = 10\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    train_one_epoch(model, optimizer, data_loader_train, device, epoch, print_freq=10)\n",
    "    lr_scheduler.step()\n",
    "    evaluate(model, data_loader_test, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
